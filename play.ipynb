{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import trimesh.transformations as TF\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Render\n",
    "Render.extIOR, Render.intIOR = 1.15, 1.0\n",
    "# Render.extIOR, Render.intIOR = 1.5, 1.0\n",
    "res=512\n",
    "Float = torch.float64\n",
    "device='cuda'\n",
    "Render.res = res\n",
    "Render.device = device\n",
    "Render.Float = Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kitten = Render.Scene(\"/root/workspace/data/kitten.obj\")\n",
    "kitten = Render.Scene(\"/root/workspace/data/kitten_vh_sim.ply\")\n",
    "kitten.set_camera((60,60), 1.1, center=(0,0,0), angles=None)\n",
    "R,K = kitten.camera_RK()\n",
    "origin, ray_dir = kitten.generate_ray()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=512x512 at 0x7F8A1C351A90>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAAAAADRE4smAAAC/0lEQVR4nO3dzVYCMQwG0L7/S8eFHn9GQWBgps137wJwoWeYpElaPDoGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAd19gVwPEEHAACGrQFAS4o7AAAAAPCTU8MWhBHaqD9e0Z1Y8x85kq6kQC+74ykhUpXYr2x/8Oo5P4a1yQBYiiULzEZdWp8YppMB8xIbAIAkpj+ARH55C1iFcgUAAABwD6cpEEwByCb+vdwZT5/+NrKN5U2xlQDJll//q1//serrucao+nhBjBrvi375hc+WiHJFDSkCAACdmO8BAAAAMgSfAwW/dQAAACCRwxAAAAAASOAkkETyHgAAAADI4lQUgBiaXjoZAAAAAARzNAIAAEBfdr0AAAAwbJABAAAAgEYceALARdokAAAAAEQph4LhSgIA0IOOBgBwE2MTAAAAZHEWAMDK9DGAhymhALn0AACAOEZAFiV14Rnq46E2i2r7Nd39/rMhEgAgk/oPrVni/CYrIMO1tT5xHZj40vpwkyGZCgDQ2L9FXheASJY+ADAJY8mZ3H2ANq6UdNWeS+QGQGvKPEAqHYCbHJIoshGezrICLlAeACCTGYAHvCBtZCKsxIqFaEpAOhnQgzhCX/+vbxWA+vPlPd/G4h6LpQxY2+a/Bd0fTgnQxvdQfuXFkQGWTLMREeAbJQGAT5oChLL4AZKVRpDrx+dI9flAkNo8j1GyYD5nhUQyAABwG3MjAADAXnZWAKl0AABgDaYWANhPPwUAYA0mVwAAgCi2gQCwi1YKAKzE7AIAAA8yTAMAAAAwLYdXz+RuAgAAAECEZY4Cl7lQAACAydlfAQDzKSNKNOEHAIAwNgEHmfZGT3thHEQGJHMMCAAAqWwGAAAA4BXsuJmX7AQAiGQMBAAIZAgEgFfTbYG5qEoAR1FxgSkoRnCC8xfe+VcAABxH5weYgWoMHEO1AQCAWbx+Ojf/AwDApAzrALzb3xH0lF7EE0kA2ZQAAC7TJXKINTDGUAwAAAAAAAAAAAAAAAAAWNEbnWjJN8zk78kAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "silhouette_edge = kitten.silhouette_edge(origin[0])\n",
    "index, output = kitten.primary_visibility(silhouette_edge, R, K, origin[0])\n",
    "image = torch.zeros((res,res))\n",
    "image[index[:,0],index[:,1]]=1\n",
    "Render.PILimage(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=512x512 at 0x7F8953E630D0>",
      "image/png": "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\n"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# kitten = Render.Scene(\"/root/workspace/data/kitten.obj\")\n",
    "kitten = Render.Scene(\"/root/workspace/data/kitten_vh_sim.ply\")\n",
    "kitten.set_camera((60,60), 1.3, center=(0,0,0), angles=None)\n",
    "R,K = kitten.camera_RK()\n",
    "origin, ray_dir = kitten.generate_ray()\n",
    "target_mask = kitten.mask(origin, ray_dir)\n",
    "Render.PILimage(target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=512x512 at 0x7F89580F11D0>",
      "image/png": "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\n"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "new_vert = kitten.vertices + torch.tensor([0.2,0.2,-0.2], device=device)\n",
    "kitten.update_verticex(new_vert)\n",
    "Render.PILimage(kitten.mask(origin, ray_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration 098: error=0.00915146"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "()"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "\n",
    "vertices = kitten.vertices\n",
    "parameter = torch.zeros(3,  device=device, requires_grad=True)\n",
    "opt = torch.optim.Adam([parameter], lr=.02)\n",
    "gif = []\n",
    "for i in range(99):\n",
    "\n",
    "    mask = kitten.mask(origin, ray_dir)\n",
    "    gif.append(Render.PILimage(mask))\n",
    "    error = (target_mask - mask).abs().mean()\n",
    "    print('Iteration %03i: error=%g' % (i, error), end='\\r')\n",
    "\n",
    "    opt.zero_grad()\n",
    "    new_vert = vertices + parameter\n",
    "    kitten.update_verticex(new_vert)\n",
    "    silhouette_edge = kitten.silhouette_edge(origin[0])\n",
    "    index, output = kitten.primary_visibility(silhouette_edge, R, K, origin[0])\n",
    "    loss = (target_mask.view((res,res))[index[:,0],index[:,1]] - output).abs().sum()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave('sil.gif',gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_target(scene:Render.Scene, deg):\n",
    "    #俯视\n",
    "    M=TF.rotation_matrix(-np.pi/180*0, [1,0,0])\n",
    "    angle = TF.euler_from_matrix(TF.rotation_matrix(np.pi/180*deg, [0,1,0]) @ M)\n",
    "    # scene.set_camera(fov=(60,60), distance = 1.0, center=(0,0.0,0), angles=angle)\n",
    "    scene.set_camera(fov=(60,60), distance = 1.1, center=(0,0.0,0), angles=angle)\n",
    "    origin, ray_dir = scene.generate_ray()\n",
    "    target, target_mask = scene.render_transparent(origin, ray_dir)\n",
    "    return target, target_mask, origin, ray_dir\n",
    "\n",
    "Target = Render.Scene(\"/root/workspace/data/kitten.obj\")\n",
    "Views = []\n",
    "# for deg in [-30,-15,0,15,30]:\n",
    "for deg in range(-90,90,45):\n",
    "    Views.append(render_target(Target, deg))\n",
    "# for deg in [-30,-15,0,15,30]:\n",
    "for deg in range(-90,90,45):\n",
    "    Views.append(render_target(Target, deg+180))\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Render.PILimage(Views[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh_vh = trimesh.load(\"/root/workspace/data/bunny.ply\")\n",
    "# mesh_vh = trimesh.load(\"/root/workspace/data/kitten.obj\")\n",
    "# mesh_vh = trimesh.load(\"/root/workspace/data/kitten_vh_sim.ply\")\n",
    "# mesh_vh = trimesh.load(\"/root/workspace/data/hand_vh_sim.ply\")\n",
    "# mesh_vh = trimesh.load(\"/root/workspace/data/hand_vh_sub.ply\")\n",
    "# mesh_vh = trimesh.load(\"/root/workspace/data/kitten_vh_sub.ply\")\n",
    "# mesh_vh.apply_transform(TF.rotation_matrix(-np.pi/2, [1,0,0]))\n",
    "# mesh_vh.export(\"result/hand_init.ply\")\n",
    "\n",
    "kitten_vh = Render.Scene(\"/root/workspace/data/kitten_vh_sim.ply\")\n",
    "vh_vertices = kitten_vh.vertices\n",
    "vh_normals = torch.tensor(kitten_vh.mesh.vertex_normals, dtype=Float, device=device)\n",
    "\n",
    "# parameter = torch.zeros((vh_vertices.shape[0],1), requires_grad=True)\n",
    "# parameter = torch.zeros(bunny_sm.vertices.shape, requires_grad=True)\n",
    "# parameter = torch.zeros([len(vh_vertices),1], dtype=Float, requires_grad=True, device=device)\n",
    "parameter = torch.zeros(vh_vertices.shape, dtype=Float, requires_grad=True, device=device)\n",
    "parameter.register_hook(kitten_vh.laplac_hook)\n",
    "opt = torch.optim.Adam([parameter], lr=.0002)\n",
    "# opt = torch.optim.SGD([parameter], lr=.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for it in range(99):\n",
    "    V_index = random.randint(0, len(Views)-1)\n",
    "    # V_index = 2\n",
    "    target, target_mask, origin, ray_dir = Views[V_index]\n",
    "    # Zero out gradients before each iteration\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # vertices = vh_vertices + parameter * vh_normals\n",
    "    vertices = vh_vertices + parameter\n",
    "    kitten_vh.update_verticex(vertices)\n",
    "    render_img, render_mask = kitten_vh.render_transparent(origin, ray_dir)\n",
    "     \n",
    "    mask = (target_mask * render_mask)\n",
    "    loss = (render_img[mask]-target[mask]).pow(2).mean()\n",
    "    kitten_vh.hook_w = 0.0\n",
    "    # laplac = 0\n",
    "    rough = 0.001*parameter.abs().mean()\n",
    "    (loss+rough).backward()\n",
    "    # loss.backward()\n",
    "\n",
    "    # Optimizer: take a gradient step\n",
    "    opt.step()\n",
    "\n",
    "    # save_image(\"result/img_{}.png\".format(it), render.detach().cpu())\n",
    "    # print('Iteration %03i: error=%g laplac=%g' % (it, loss, laplac_hook.rough), end='\\r')\n",
    "    print('Iteration %03i: error=%g rough=%g hook=%g' % (it, loss, rough, kitten_vh.hook_rough), end='\\r')\n",
    "    # imageio.imsave(\"result/disp_{}.png\".format(it), parameter.detach().cpu())\n",
    "    \n",
    "\n",
    "# imageio.imsave(\"displacment.png\", parameter.detach().cpu())\n",
    "# save_image(\"result/optim.png\", render.detach())\n",
    "# mesh_vh.export(\"result/hand_optim.ply\")\n",
    "# _=mesh_vh.export(\"hand_optim.ply\")\n",
    "# _=mesh_vh.export(\"kitten_optim.ply\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Render.PILimage(render_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_vh = trimesh.load(\"/root/workspace/data/hand_vh_sim.ply\")\n",
    "vh_vertices = torch.tensor(mesh_vh.vertices, dtype=Float, device=device)\n",
    "neighbors=mesh_vh.vertex_neighbors\n",
    "col = np.concatenate(neighbors)\n",
    "row = np.concatenate([[i] * len(n) for i, n in enumerate(neighbors)])\n",
    "data = np.concatenate([[1.0 / len(n)] * len(n) for n in neighbors])\n",
    "col = torch.tensor(col, device=device)\n",
    "row = torch.tensor(row, device=device)\n",
    "i = torch.stack((row,col))\n",
    "data = torch.tensor(data, dtype=Float, device=device)\n",
    "SM_size = torch.Size([len(vertices),len(vertices)])\n",
    "weightM=torch.sparse.FloatTensor(i, data, SM_size)\n",
    "iterations = 10\n",
    "lamb = 0.5\n",
    "for _index in range(iterations):\n",
    "    # vol_ini = mesh_vh.volume\n",
    "    laplac = vh_vertices - weightM.mm(vh_vertices)\n",
    "    vh_vertices -= lamb * laplac\n",
    "    mesh_vh.vertices = vh_vertices.detach().cpu().numpy()\n",
    "    # vol_new = mesh_vh.volume\n",
    "    # vh_vertices *= ((vol_ini / vol_new) ** (1.0 / 3.0))\n",
    "mesh_vh.vertices = vh_vertices.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=mesh_vh.export(\"hand_sm.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}